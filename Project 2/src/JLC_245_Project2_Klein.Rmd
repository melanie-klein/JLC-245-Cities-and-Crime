---
title: "JLC_245_Project2_Klein"
author: "Melanie Klein"
date: "`r Sys.Date()`"
output: html_document
---
```{r Install Packages, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
install.packages('tidyverse')
install.packages('leaflet')
install.packages('tidycensus')
install.packages(c("cowplot", "ggrepel", "rgeos", "sf", "maps", "usmap", "ggspatial", "libwgeom", "rnaturalearth", "rnaturalearthdata"))
```

```{r Load Packages, message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(leaflet)
library(tidycensus)
library(rnaturalearth)
library(rnaturalearthdata)
library(maps)
library(lubridate)
library(usmap)
library(sf)
theme_set(theme_bw())
```

```{r Get Data, message=FALSE, warning=FALSE, include=FALSE}
wapo.data <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv", stringsAsFactors = FALSE)
```

```{r Clean Data, message=FALSE, warning=FALSE, include=FALSE}
wapo.data$date <- as.Date(wapo.data$date) # Convert the date to a date format
wapo.data$month <- substr(wapo.data$date, 6, 7) # Create a Month field
wapo.data$year <- substr(wapo.data$date, 0, 4) # Create a Year field
wapo.data$yearmonth <- paste(wapo.data$year, wapo.data$month, sep = "-") # Calculate a combination of Year and Month
wapo.data$statecity <- paste(wapo.data$state, wapo.data$city, sep = "-") # Calculate a combination of State and City
unique(wapo.data$race) # Before adjusting multiple races
wapo.data$race <- gsub("W;B;N|N;H|W;H|B;H|W;B|W;A", "O", wapo.data$race) # Adjust multiple races
unique(wapo.data$race) # After adjusting multiple races
wapo.data.map <- subset(wapo.data, !is.na(wapo.data$latitude)) # Remove records without latitude (and longitude)
```

```{r Summarize Data, echo=FALSE, message=FALSE, warning=FALSE}
# race
sum.race <- wapo.data %>%
  group_by(race) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# city
sum.city <- wapo.data %>%
  group_by(statecity) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# year
sum.year <- wapo.data %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# state
sum.state <- wapo.data %>%
  group_by(state) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# manner of death
sum.mannerofdeath <- wapo.data %>%
  group_by(threat_type) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# armed
sum.armed <- wapo.data %>%
  group_by(armed_with) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# gender
sum.gender <- wapo.data %>%
  group_by(gender) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# signs of mental illness
sum.mentalillness <- wapo.data %>%
  group_by(was_mental_illness_related) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# flee
sum.flee <- wapo.data %>%
  group_by(flee_status) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# body camera
sum.bodycamera <- wapo.data %>%
  group_by(body_camera) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# year-month
sum.yearmonth <- wapo.data %>%
  group_by(yearmonth) %>%
  summarise(count = n()) %>%
  mutate(pct = round(count/sum(count)*100,2))
# race and mental
sum.race.mental <- wapo.data %>% 
  group_by(race, was_mental_illness_related) %>% 
  summarise(count = n()) %>% mutate(pct = count/sum(count)*100)
```

```{r}
ggplot(wapo.data) +
  geom_bar(aes(x = race), stat = "count", fill = "blue")
```

```{r}
ggplot(sum.race.mental, aes(x = factor(race), y = pct, fill = factor(was_mental_illness_related))) + 
  geom_bar(stat="identity", width = 0.7) + 
  labs(title = "Police Shootings by Race and Mental Illness",
       x = "Race", 
       y = "percent", 
       fill = "Mental Illness Related") + 
  theme_minimal(base_size = 14)
```

```{r}
ggplot(wapo.data) + geom_bar(aes(x = was_mental_illness_related), stat = "count", fill = "orange") + facet_wrap(~ race, nrow = 3)
```
```{r}
### maps
world <- ne_countries(scale = "medium", returnclass = "sf") # this builds a list of countries
states <- st_as_sf(map("state", plot = FALSE, fill = TRUE)) # this cleans up the US states

# transparent points
ggplot(data = world) + 
  geom_sf(data = states, fill = NA) + 
  geom_point(data = wapo.data.map, aes(x = longitude, y = latitude), 
             size = 2, alpha = 0.025) + 
  coord_sf(xlim = c(-130, -65), ylim = c(25, 50), expand = FALSE)
```

```{r}
ggplot(data = world) + 
  geom_sf(data = states, fill = NA) + 
  geom_point(data = wapo.data.map, aes(x = longitude, y = latitude), 
             size = 2, alpha = 0.025) + 
  coord_sf(xlim = c(-130, -65), ylim = c(25, 50), expand = FALSE) +
  facet_wrap(~race, nrow = 3)
```

```{r}
leaflet(wapo.data.map) %>%
  addTiles() %>%
  addMarkers(lng = ~longitude, lat = ~latitude, clusterOptions = markerClusterOptions())
```

```{r API key}
census_api_key("794f37c27092be60b131e4f207abcf950f227f38", install = TRUE, overwrite = TRUE)
```
```{r third and fourth}
readRenviron("~/.Renviron")
# load the list of variables
census.variables.2023 <- load_variables(2023, "acs5", cache = TRUE)
# query some race statistics
race.2023 <- get_acs(geography = "state", variables = c("B02008_001", "B02009_001", "B02010_001", "B02011_001", "B03001_003"), year = 2023)
race.2023$variable <- gsub("B02008_001", "White", race.2023$variable)
race.2023$variable <- gsub("B02009_001", "Black", race.2023$variable)
race.2023$variable <- gsub("B02010_001", "Native American", race.2023$variable)
race.2023$variable <- gsub("B02011_001", "Asian", race.2023$variable)
race.2023$variable <- gsub("B03001_003", "Hispanic", race.2023$variable)
race.total <- get_acs(geography = "us", variables = c("B02008_001", "B02009_001", "B02010_001", "B02011_001", "B03001_003"), year = 2023)
race.total$variable <- gsub("B02008_001", "White", race.total$variable)
```
```{r fifth}
# Fifth, query some population statistics:
totalpop.2023 <- get_acs(geography = "state", variables = "B01003_001", year = 2023)
# Rename the columns:
names(totalpop.2023) <- c("GEOID", "State", "Variable", "Population", "junk")
# Calculate the percentage of the total population for each state:
totalpop.2023$State.PCT <- round(totalpop.2023$Population/sum(totalpop.2023$Population)*100, 2)
```
```{r sixth}
# Sixth, join the total population to the race table:
temp.race.population <- race.2023 %>% left_join(totalpop.2023, by = "GEOID")
# left_join merges the columns from the population table to the race table, using the ‘GEOID’ as the common field
# Only keep the relevant columns:
race.population <- temp.race.population[c(1:4,8,10)]
# Rename them:
names(race.population) <- c("GEOID", "State", "Race", "Population.Race", "Population.State", "State.PCT")
# And then calculate the percentage of the total population for each race:
race.population$Race.PCT <- round(race.population$Population.Race/race.population$Population.State*100, 2)
```

```{r seventh}
# Seventh, add a percentage to the nationwide race table:
race.total$PCT <- race.total$estimate/sum(totalpop.2023$Population)*100
# Notice, we are using the sum of the state populations from another table to calculate the values for this table
# Rename the columns:
names(race.total) <- c("GEOID", "Area", "Race", "Count", "moe", "Race.PCT")
```

```{r eigth}
# First, the race table:
sum.race$race <- gsub("W", "White", sum.race$race)
sum.race$race <- gsub("B", "Black", sum.race$race)
sum.race$race <- gsub("A", "Asian", sum.race$race)
sum.race$race <- gsub("N", "Native American", sum.race$race)
sum.race$race <- gsub("H", "Hispanic", sum.race$race)
sum.race$race <- gsub("O", "Other", sum.race$race)
# Rename the columns:
names(sum.race) <- c("Race", "Count", "Shooting.PCT")
# Second, the state table:
# Change the abbreviations to full names
sum.state$State.Name <- state.name[match(wapo.state$state,state.abb)]
# Fix DC!
wapo.state$State.Name <- replace_na(wapo.state$State.Name, "District of Columbia")
# Rename the columns:
names(wapo.state) <- c("oldstate", "Count", "Shooting.PCT", "State")
```

```{r ninth}
wapo.census.race <- wapo.race %>% left_join(race.total, by = "Race")
# Remove unnecessary columns
# Rename the remaining columns
```

```{r tenth}
wapo.census.state <- wapo.state %>% left_join(totalpop.2023, by = "State")
# Remove unnecessary columns
# Rename the remaining columns
```

metadata available in GitHub page
10,428 events since 2015
started January 2 2015, most recent is Dec 31 2024
averages 1043 police shootings every year
about 1100 without location data

header for data - 1 paragraph
header for methods - 1 paragraph
header for analysis - 5 paragraphs
  city 1 + visual
    What is the city
    Reason one it’s similar
    Stat 2
    Reason two
    Stat 2
  city 2 + visual
  city 3 + visual
  city 4 + visual
  city 5 + visual
  
identify similar cities: look at
  events - look at a comparison to DC
  victims - filtering and decisions to be made there. look at DC events and see what stands out versus normal in this area
  locations - location types where they happened, hotspots
  totals vs trends - 
  
fatal police shootings aren't happening consistently across races
  
if talking about census data, need to talk about state race comparisons to US population in findings

don't talk about cities in methods. data is how. methods is how. findings are when you talk about cities.

make sure map and findings match. include visuals directly in analysis.




```{r packages, message=FALSE, warning=FALSE}
# install.packages('R.utils')
# install.packages('geojsonsf')

library(data.table)
library(tidyverse)
library(sf)
library(geojsonsf)
library(tidycensus)
```

```{r election data 2024, message=FALSE, warning=FALSE}
election.2024 <- fread("https://int.nyt.com/newsgraphics/elections/map-data/2024/national/precincts-with-results.csv.gz")
election.2024 <- separate(election.2024,
                          GEOID,
                          into = c("FIPS", "PRECINT", "PRECINT.NAME"),
                          sep = "-")
names(election.2024) <- c("state", "FIPS", "PRECINT",
                          "PRECINT.NAME", "votes_dem_2024", "votes_rep_2024",
                          "votes_total_2024", "pct_dem_lead_2024", "official boundary")
election.2024$pct_dem_lead_2024 <- election.2024$pct_dem_lead_2024 * 100

summary.2024 <- election.2024 %>%
  group_by(FIPS) %>%
  summarise(sum(votes_dem_2024), sum(votes_rep_2024), sum(votes_total_2024))

names(summary.2024) <- c("FIPS", "votes_dem_2024", "votes_rep_2024", "votes_total_2024")
```

```{r election data 2020, message=FALSE, warning=FALSE}
url.2020 <- 'https://int.nyt.com/newsgraphics/elections/map-data/2020/national/precincts-with-results.geojson.gz'
file.2020 <- gzcon(url(url.2020, 'rb'))
election.2020 <- geojson_sf(file.2020)
election.2020 <- separate(election.2020,
                          GEOID,
                          into = c("FIPS", "NAME", "EXTRA"))
names(election.2020) <- c("FIPS", "NAME", "EXTRA", "votes_dem_2020", "votes_rep_2020", "votes_total_2020", "votes_per_sqkm_2020", "pct_dem_lead_2024", "geometry")

#summary.2020 <- election.2020 %>%
#  group_by(FIPS) %>%
#  summarise(sum(votes_dem_2020), sum(votes_rep_2020), sum(votes_total_2020))

#names(summary.2020) <- c("FIPS", "votes_dem_2020", "votes_rep_2020", "votes_total_2020")
```

```{r census master codes and map, message=FALSE, warning=FALSE}
fips.subset <- c(19097, 17155, 50009, 27055, 39143, 55113, 44003, 55011, 19105, 46109, 19179, 55099, 51057)

maps::county.fips %>%
  as_tibble %>% 
  extract(polyname, c("region", "subregion"), "^([^,]+),([^,]+)$") ->
  fips.clean

map_data("county") %>% 
  left_join(fips.clean) ->
  fips.all

fips.all %>% 
  mutate(counties = fips %in% fips.subset) %>% 
  ggplot(aes(long, lat, group = group)) +
  geom_polygon(aes(fill=counties), color="gray70") +
  coord_map() +
  scale_fill_manual(values=c("TRUE"="red", "FALSE"="gray90"))
```